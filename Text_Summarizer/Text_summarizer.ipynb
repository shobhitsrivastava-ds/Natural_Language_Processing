{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT LIBRARIES TO IMPORT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnlinkintopara(link):\n",
    "    scraped_data=urilib.request.urlopen(\"link\")\n",
    "    article=scraped_data.read()\n",
    "    parsed_article = bs.BeautifulSoup(article,\"lxml\")\n",
    "    paragraph=parsed_article.find_all(\"p\").text\n",
    "    article_text=\"\"\n",
    "    for p in paragraph:\n",
    "        article_text+=p\n",
    "    return(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=\"\"\n",
    "article_text=turnlinkintopara(link)\n",
    "def furthurprocessing(article_text):\n",
    "    formatted_article=re.sub(\"[^a-zA-Z]\",\" \",article_text)\n",
    "    formatted_article=re.sub(r\"\\s+\",\" \",formatted_article)\n",
    "    return(formatted_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_article=furthurprocessing(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_token=nltk.sent_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "word_freq={}\n",
    "for word in nltk.word_tokenize(formatted_article):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_freq[word]=1\n",
    "        else:\n",
    "            word_freq[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_freq=max(word_freq.values())\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word]=(word_freq[word]/max_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores={}\n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_freq.keys():\n",
    "            if len(sent.split(\" \"))<30:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent]=word_freq[word]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_freq[word]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #use the heapq library and call its nlargest function to retrieve the top 7 sentences with the highest scores.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "summary_sentences=heapq.nlargest(7,sentence_scores,key=sentence_scores.get)\n",
    "summary=\" \".join(summary_sentences)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
